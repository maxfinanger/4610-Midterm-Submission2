{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e4271e",
   "metadata": {},
   "source": [
    "# Multi-Objective Capacitated VRP (MOVRP) Problem Using Multi-Objective Evolutionary Algorithms (MOEAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641a026",
   "metadata": {},
   "source": [
    "### Global Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786614",
   "metadata": {},
   "source": [
    "Global function that is used by both algorithms for reading the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_vrp_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse a Vehicle Routing Problem (VRP) files.\n",
    "    \n",
    "    This function reads and parses VRP files containing problem instances with:\n",
    "    - Problem metadata (name, type, dimension, capacity, etc.)\n",
    "    - Node coordinates in 2D Euclidean space\n",
    "    - Customer demand values\n",
    "    - Depot location(s)\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the VRP file to be parsed\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing parsed VRP data with keys:\n",
    "            - 'metadata': Dictionary of problem metadata (name, capacity, etc.)\n",
    "            - 'coords': List of (x, y) coordinate tuples, 0-based indexing\n",
    "            - 'demands': List of demand values for each node, 0-based indexing\n",
    "            - 'depots': List of depot indices, 0-based indexing\n",
    "            - 'dist_matrix': 2D numpy array of Euclidean distances between all nodes\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f: \n",
    "        lines = f.readlines()  # Read all lines into memory\n",
    "\n",
    "    # Strip whitespace and filter empty lines for clean parsing\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    metadata = {}  # Dictionary to store problem metadata\n",
    "    i = 0  # Line index counter for sequential parsing\n",
    "    \n",
    "    # Continue parsing metadata until we reach the coordinates section\n",
    "    while not lines[i].startswith('NODE_COORD_SECTION'):\n",
    "        if ':' in lines[i]:  # Check if line contains metadata key-value pair\n",
    "            key, value = lines[i].split(':', 1)  # Split on first colon only\n",
    "            metadata[key.strip()] = value.strip().strip('\"')  # Store cleaned key-value pair\n",
    "        i += 1  # Move to next line\n",
    "\n",
    "    coords = []  # List to store (x, y) coordinate tuples\n",
    "    i += 1  # Skip the 'NODE_COORD_SECTION' header line\n",
    "    \n",
    "    # Parse coordinates until we reach the demand section\n",
    "    while not lines[i].startswith('DEMAND_SECTION'):\n",
    "        parts = lines[i].split()  # Split line into components\n",
    "        if len(parts) == 3:  # Valid coordinate line: node_id x y\n",
    "            node_id = int(parts[0]) - 1  # Convert to 0-based indexing\n",
    "            x, y = int(parts[1]), int(parts[2])  # Extract coordinates\n",
    "            \n",
    "            # Ensure coords list is large enough for this node_id\n",
    "            while len(coords) <= node_id:\n",
    "                coords.append(None)  # Fill with None placeholders\n",
    "            coords[node_id] = (x, y)  # Store coordinate tuple at correct index\n",
    "        i += 1  # Move to next line\n",
    "\n",
    "    # Parse customer demands (convert from 1-based to 0-based indexing)\n",
    "    demands = []  # List to store demand values for each node\n",
    "    i += 1  # Skip the 'DEMAND_SECTION' header line\n",
    "    \n",
    "    # Parse demands until we reach the depot section\n",
    "    while not lines[i].startswith('DEPOT_SECTION'):\n",
    "        parts = lines[i].split()  # Split line into components\n",
    "        if len(parts) == 2:  # Valid demand line: node_id demand_value\n",
    "            node_id = int(parts[0]) - 1  # Convert to 0-based indexing\n",
    "            demand = int(parts[1])  # Extract demand value\n",
    "            \n",
    "            # Ensure demands list is large enough for this node_id\n",
    "            while len(demands) <= node_id:\n",
    "                demands.append(None)  # Fill with None placeholders\n",
    "            demands[node_id] = demand  # Store demand at correct index\n",
    "        i += 1  # Move to next line\n",
    "\n",
    "    # Parse depot locations (convert from 1-based to 0-based indexing)\n",
    "    depots = []  # List to store depot node indices\n",
    "    i += 1  # Skip the 'DEPOT_SECTION' header line\n",
    "    \n",
    "    # Parse depot indices until EOF or -1 terminator\n",
    "    while i < len(lines) and lines[i] != 'EOF':\n",
    "        depot = int(lines[i])  # Parse depot node number\n",
    "        if depot == -1:  # -1 indicates end of depot list\n",
    "            break\n",
    "        depots.append(depot - 1)  # Convert to 0-based and store\n",
    "        i += 1  # Move to next line\n",
    "\n",
    "    # Compute Euclidean distance matrix for all node pairs\n",
    "    dimension = int(metadata.get('DIMENSION', len(coords)))  # Get problem dimension\n",
    "    dist_matrix = np.zeros((dimension, dimension))  # Initialize distance matrix\n",
    "    \n",
    "    # Calculate pairwise distances using Euclidean formula\n",
    "    for a in range(dimension):  # For each node a\n",
    "        for b in range(dimension):  # For each node b\n",
    "            x1, y1 = coords[a]  # Get coordinates of node a\n",
    "            x2, y2 = coords[b]  # Get coordinates of node b\n",
    "            # Calculate Euclidean distance: sqrt((x2-x1)² + (y2-y1)²)\n",
    "            dist_matrix[a][b] = math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "    # Return structured data dictionary\n",
    "    return {\n",
    "        'metadata': metadata,  # Problem metadata (capacity, name, etc.)\n",
    "        'coords': coords,  # List of (x, y) tuples, 0-based (index 0 = node 1)\n",
    "        'demands': demands,  # List of demand integers, 0-based\n",
    "        'depots': depots,  # List of depot indices, 0-based (usually [0] for depot at node 1)\n",
    "        'dist_matrix': dist_matrix  # 2D numpy array of Euclidean distances\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41a893",
   "metadata": {},
   "source": [
    "## NSGA-II Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSGAII:\n",
    "    \"\"\"\n",
    "    Non-dominated Sorting Genetic Algorithm II (NSGA-II) for Multi-Objective Vehicle Routing Problem.\n",
    "    \n",
    "    NSGA-II is a multi-objective evolutionary algorithm that uses non-dominated sorting and \n",
    "    crowding distance to maintain diversity in the Pareto front. This implementation is \n",
    "    specifically designed for the Capacitated Vehicle Routing Problem (CVRP) with two objectives:\n",
    "    1. Minimize total distance traveled by all vehicles\n",
    "    2. Minimize route imbalance (standard deviation of route lengths)\n",
    "    \n",
    "    The algorithm uses a permutation-based representation where each individual represents\n",
    "    a sequence of customers that is then split into feasible routes using capacity constraints.\n",
    "    Uses insert mutation which is particularly effective for VRP problems.\n",
    "    \n",
    "    Attributes:\n",
    "        data (dict): Parsed VRP problem data containing coordinates, demands, distance matrix\n",
    "        pop_size (int): Population size for the evolutionary algorithm\n",
    "        generations (int): Number of generations to evolve\n",
    "        crossover_rate (float): Probability of crossover operation\n",
    "        mutation_rate (float): Probability of mutation operation\n",
    "        population (list): Current population of individuals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, pop_size=20, generations=10, crossover_rate=0.7, mutation_rate=0.2):\n",
    "        \"\"\"\n",
    "        Initialize NSGA-II algorithm with problem data and parameters.\n",
    "        \n",
    "        Args:\n",
    "            data (dict): VRP problem data from parse_vrp_file()\n",
    "            pop_size (int, optional): Population size. Defaults to 20.\n",
    "            generations (int, optional): Number of generations. Defaults to 10.\n",
    "            crossover_rate (float, optional): Crossover probability. Defaults to 0.7.\n",
    "            mutation_rate (float, optional): Mutation probability. Defaults to 0.2.\n",
    "        \"\"\"\n",
    "        self.data = data  # Store problem instance data\n",
    "        self.pop_size = pop_size  # Number of individuals in population\n",
    "        self.generations = generations  # Number of evolutionary generations\n",
    "        self.crossover_rate = crossover_rate  # Probability of applying crossover\n",
    "        self.mutation_rate = mutation_rate  # Probability of applying mutation\n",
    "        self.population = []  # Initialize empty population\n",
    "\n",
    "        # Pre-compute frequently accessed values for performance optimization\n",
    "        self.dist_matrix = self.data['dist_matrix']  # Distance matrix between all nodes\n",
    "        self.capacity = int(self.data['metadata']['CAPACITY'])  # Vehicle capacity constraint\n",
    "        self.demands = self.data['demands']  # Customer demand values\n",
    "        self.n_customers = len(self.data['coords']) - 1  # Number of customers (excluding depot)\n",
    "        self.customer_range = list(range(1, self.n_customers + 1))  # Customer indices (1-based)\n",
    "\n",
    "    def split_routes(self, customer_sequence):\n",
    "        \"\"\"\n",
    "        Split a customer sequence into feasible routes using capacity constraints.\n",
    "        \n",
    "        This method implements the route-first, cluster-second approach where a giant tour\n",
    "        of customers is split into multiple vehicle routes based on capacity limits.\n",
    "        Each route starts and ends at the depot (node 0).\n",
    "        \n",
    "        Args:\n",
    "            customer_sequence (list): Sequence of customer indices to visit\n",
    "            \n",
    "        Returns:\n",
    "            list: List of routes, where each route is a list starting and ending with depot (0)\n",
    "        \"\"\"\n",
    "        routes, route, load = [], [0], 0  # Initialize route list, current route, current load\n",
    "        \n",
    "        for customer in customer_sequence:  # Process each customer in sequence\n",
    "            demand = self.demands[customer]  # Get customer's demand\n",
    "            \n",
    "            if load + demand > self.capacity:  # Check if adding customer exceeds capacity\n",
    "                route.append(0)  # Close current route by returning to depot\n",
    "                routes.append(route)  # Add completed route to route list\n",
    "                route, load = [0, customer], demand  # Start new route with this customer\n",
    "            else:\n",
    "                route.append(customer)  # Add customer to current route\n",
    "                load += demand  # Update current load\n",
    "                \n",
    "        route.append(0)  # Close final route by returning to depot\n",
    "        routes.append(route)  # Add final route to route list\n",
    "        return routes\n",
    "\n",
    "    def calculate_route_distance(self, route):\n",
    "        \"\"\"\n",
    "        Calculate the total distance for a single route.\n",
    "        \n",
    "        Args:\n",
    "            route (list): Route as list of node indices\n",
    "            \n",
    "        Returns:\n",
    "            float: Total distance traveled in this route\n",
    "        \"\"\"\n",
    "        return sum(self.dist_matrix[route[i], route[i+1]] for i in range(len(route) - 1))\n",
    "\n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"\n",
    "        Evaluate an individual's fitness using two objectives for MOVRP.\n",
    "        \n",
    "        Args:\n",
    "            individual (dict): Individual containing routes and other data\n",
    "        \"\"\"\n",
    "        if individual['objectives'] is not None:  # Skip if already evaluated\n",
    "            return\n",
    "            \n",
    "        routes = individual['routes']  # Get individual's route structure\n",
    "        route_distances = [self.calculate_route_distance(route) for route in routes]  # Calculate each route's distance\n",
    "        total_dist = sum(route_distances)  # Objective 1: Total distance\n",
    "        \n",
    "        if len(route_distances) > 1:  # Calculate balance only if multiple routes\n",
    "            mean_length = total_dist / len(route_distances)  # Average route length\n",
    "            variance = sum((d - mean_length)**2 for d in route_distances) / len(route_distances)  # Variance calculation\n",
    "            route_balance = variance**0.5  # Objective 2: Standard deviation (route imbalance)\n",
    "        else:\n",
    "            route_balance = 0.0  # Single route has perfect balance\n",
    "            \n",
    "        individual['objectives'] = [total_dist, route_balance]  # Store both objectives\n",
    "\n",
    "    def evaluate_population(self, population):\n",
    "        \"\"\"\n",
    "        Evaluate fitness for all individuals in the population.\n",
    "        \n",
    "        Args:\n",
    "            population (list): List of individuals to evaluate\n",
    "        \"\"\"\n",
    "        for individual in population:  # Process each individual\n",
    "            self.evaluate_individual(individual)  # Calculate objectives\n",
    "\n",
    "    def generate_initial_population(self):\n",
    "        \"\"\"\n",
    "        Generate initial population using heuristics and random solutions.\n",
    "        \n",
    "        Returns:\n",
    "            list: Initial population of individuals\n",
    "        \"\"\"\n",
    "        population = []  # Initialize empty population\n",
    "        \n",
    "        # Add heuristic solutions for better starting points if population size allows\n",
    "        if self.pop_size >= 2:\n",
    "            nn_seq = self.nearest_neighbor_solution()  # Distance-optimized solution\n",
    "            population.append(self.create_individual(nn_seq))  # Add to population\n",
    "            \n",
    "            bal_seq = self.balanced_insertion_solution()  # Balance-optimized solution\n",
    "            population.append(self.create_individual(bal_seq))  # Add to population\n",
    "            \n",
    "            # Fill remaining population with random permutations\n",
    "            for _ in range(self.pop_size - 2):\n",
    "                perm = self.customer_range[:]  # Copy customer list\n",
    "                random.shuffle(perm)  # Random permutation\n",
    "                population.append(self.create_individual(perm))  # Add to population\n",
    "        else:\n",
    "            # If population size is small, use only random solutions\n",
    "            for _ in range(self.pop_size):\n",
    "                perm = self.customer_range[:]  # Copy customer list\n",
    "                random.shuffle(perm)  # Random permutation\n",
    "                population.append(self.create_individual(perm))  # Add to population\n",
    "                \n",
    "        return population\n",
    "\n",
    "    def nearest_neighbor_solution(self):\n",
    "        \"\"\"\n",
    "        Generate a distance-optimized solution using nearest neighbor heuristic.\n",
    "        \n",
    "        Returns:\n",
    "            list: Customer sequence optimized for minimal total distance\n",
    "        \"\"\"\n",
    "        unvisited = set(self.customer_range)  # Set of unvisited customers\n",
    "        solution = []  # Customer sequence being built\n",
    "        current = 0  # Start from depot\n",
    "        \n",
    "        while unvisited:  # Continue until all customers visited\n",
    "            # Calculate distances from current location to all unvisited customers\n",
    "            distances = [(self.dist_matrix[current, customer], customer)\n",
    "                        for customer in unvisited]\n",
    "            _, next_customer = min(distances)  # Select nearest customer\n",
    "            solution.append(next_customer)  # Add to sequence\n",
    "            unvisited.remove(next_customer)  # Mark as visited\n",
    "            current = next_customer  # Move to selected customer\n",
    "            \n",
    "        return solution\n",
    "\n",
    "    def balanced_insertion_solution(self):\n",
    "        \"\"\"\n",
    "        Generate a balance-focused solution using distance-based alternating insertion.\n",
    "        \n",
    "        Returns:\n",
    "            list: Customer sequence optimized for route balance\n",
    "        \"\"\"\n",
    "        # Sort customers by distance from depot\n",
    "        customers_by_distance = [(self.dist_matrix[0, c], c) for c in self.customer_range]\n",
    "        customers_by_distance.sort()  # Sort by increasing distance\n",
    "        \n",
    "        solution = []  # Initialize solution sequence\n",
    "        # Split into near and far customers\n",
    "        near = [c for _, c in customers_by_distance[:len(customers_by_distance)//2]]\n",
    "        far = [c for _, c in customers_by_distance[len(customers_by_distance)//2:]]\n",
    "        \n",
    "        # Alternate between near and far customers for balance\n",
    "        for i in range(max(len(near), len(far))):\n",
    "            if i < len(near):  # Add near customer if available\n",
    "                solution.append(near[i])\n",
    "            if i < len(far):  # Add far customer if available\n",
    "                solution.append(far[i])\n",
    "                \n",
    "        return solution\n",
    "\n",
    "    def fast_non_dominated_sort(self, population):\n",
    "        \"\"\"\n",
    "        Perform non-dominated sorting to rank individuals by Pareto dominance.\n",
    "        \n",
    "        Args:\n",
    "            population (list): Population to sort and rank\n",
    "        \"\"\"\n",
    "        n = len(population)  # Population size\n",
    "        objectives = [ind['objectives'] for ind in population]  # Extract objective values\n",
    "        domination_count = [0] * n  # Count of solutions that dominate each individual\n",
    "        dominated_solutions = [[] for _ in range(n)]  # Lists of solutions dominated by each individual\n",
    "        \n",
    "        # Compare all pairs to determine dominance relationships\n",
    "        for i in range(n):\n",
    "            obj1_i, obj2_i = objectives[i]  # Objectives of individual i\n",
    "            for j in range(i + 1, n):  # Only check upper triangle to avoid duplicates\n",
    "                obj1_j, obj2_j = objectives[j]  # Objectives of individual j\n",
    "                \n",
    "                # Check if i dominates j\n",
    "                if (obj1_i <= obj1_j and obj2_i <= obj2_j) and (obj1_i < obj1_j or obj2_i < obj2_j):\n",
    "                    dominated_solutions[i].append(j)  # i dominates j\n",
    "                    domination_count[j] += 1  # j is dominated by one more solution\n",
    "                # Check if j dominates i\n",
    "                elif (obj1_j <= obj1_i and obj2_j <= obj2_i) and (obj1_j < obj1_i or obj2_j < obj2_i):\n",
    "                    dominated_solutions[j].append(i)  # j dominates i\n",
    "                    domination_count[i] += 1  # i is dominated by one more solution\n",
    "        \n",
    "        # Identify first front (non-dominated solutions)\n",
    "        current_front = [i for i in range(n) if domination_count[i] == 0]\n",
    "        rank = 1  # Start with rank 1\n",
    "        \n",
    "        # Assign rank 1 to non-dominated solutions\n",
    "        for i in current_front:\n",
    "            population[i]['rank'] = rank\n",
    "        \n",
    "        # Process remaining fronts iteratively\n",
    "        while current_front:\n",
    "            next_front = []  # Solutions for next rank level\n",
    "            \n",
    "            # For each solution in current front, reduce domination count of dominated solutions\n",
    "            for i in current_front:\n",
    "                for j in dominated_solutions[i]:  # For each solution dominated by i\n",
    "                    domination_count[j] -= 1  # Reduce domination count\n",
    "                    if domination_count[j] == 0:  # If no longer dominated\n",
    "                        next_front.append(j)  # Add to next front\n",
    "            \n",
    "            if next_front:  # If there are solutions for next rank\n",
    "                rank += 1  # Increment rank\n",
    "                for i in next_front:  # Assign new rank\n",
    "                    population[i]['rank'] = rank\n",
    "                    \n",
    "            current_front = next_front  # Move to next front\n",
    "\n",
    "    def calculate_crowding_distance(self, population):\n",
    "        \"\"\"\n",
    "        Calculate crowding distance for diversity preservation in NSGA-II.\n",
    "        \n",
    "        Args:\n",
    "            population (list): Population with assigned ranks\n",
    "        \"\"\"\n",
    "        # Initialize crowding distance to zero for all individuals\n",
    "        for ind in population:\n",
    "            ind['crowding_distance'] = 0.0\n",
    "        \n",
    "        # Group individuals by rank for separate processing\n",
    "        rank_groups = {}\n",
    "        for i, ind in enumerate(population):\n",
    "            rank = ind['rank']  # Get individual's rank\n",
    "            if rank not in rank_groups:\n",
    "                rank_groups[rank] = []  # Initialize rank group\n",
    "            rank_groups[rank].append(i)  # Add individual index to rank group\n",
    "        \n",
    "        # Process each rank separately\n",
    "        for indices in rank_groups.values():\n",
    "            n_front = len(indices)  # Number of solutions in this front\n",
    "            \n",
    "            # Special case: small fronts get infinite distance\n",
    "            if n_front <= 2:\n",
    "                for i in indices:\n",
    "                    population[i]['crowding_distance'] = float('inf')\n",
    "                continue\n",
    "            \n",
    "            # Calculate crowding distance for each objective\n",
    "            for obj_idx in range(2):  # For both objectives\n",
    "                # Sort solutions by current objective value\n",
    "                indices.sort(key=lambda i: population[i]['objectives'][obj_idx])\n",
    "                \n",
    "                # Boundary solutions get infinite distance\n",
    "                population[indices[0]]['crowding_distance'] = float('inf')  # Minimum\n",
    "                population[indices[-1]]['crowding_distance'] = float('inf')  # Maximum\n",
    "                \n",
    "                # Calculate range of objective values in this front\n",
    "                obj_range = population[indices[-1]]['objectives'][obj_idx] - population[indices[0]]['objectives'][obj_idx]\n",
    "                \n",
    "                if obj_range > 0:  # Avoid division by zero\n",
    "                    # Calculate distance for interior solutions\n",
    "                    for j in range(1, n_front - 1):\n",
    "                        i = indices[j]  # Current solution index\n",
    "                        \n",
    "                        if population[i]['crowding_distance'] != float('inf'):\n",
    "                            # Distance = normalized gap between neighbors\n",
    "                            prev_obj = population[indices[j-1]]['objectives'][obj_idx]\n",
    "                            next_obj = population[indices[j+1]]['objectives'][obj_idx]\n",
    "                            population[i]['crowding_distance'] += (next_obj - prev_obj) / obj_range\n",
    "\n",
    "    def tournament_selection(self, population, tournament_size=2):\n",
    "        \"\"\"\n",
    "        Select parent using tournament selection based on NSGA-II criteria.\n",
    "        \n",
    "        Args:\n",
    "            population (list): Population to select from\n",
    "            tournament_size (int, optional): Number of individuals in tournament. Defaults to 2.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Selected individual for reproduction\n",
    "        \"\"\"\n",
    "        tournament = random.sample(population, tournament_size)  # Random tournament\n",
    "        # Select best: minimize rank, maximize crowding distance\n",
    "        return min(tournament, key=lambda x: (x['rank'], -x['crowding_distance']))\n",
    "\n",
    "    def create_individual(self, customer_sequence):\n",
    "        \"\"\"\n",
    "        Create an individual from a customer sequence.\n",
    "        \n",
    "        Args:\n",
    "            customer_sequence (list): Sequence of customer indices\n",
    "            \n",
    "        Returns:\n",
    "            dict: Complete individual structure\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'customer_sequence': customer_sequence,  # Permutation representation\n",
    "            'routes': self.split_routes(customer_sequence),  # Convert to actual routes\n",
    "            'objectives': None,  # Fitness values (calculated later)\n",
    "            'rank': None,  # Dominance rank (assigned during sorting)\n",
    "            'crowding_distance': 0.0  # Diversity measure (calculated later)\n",
    "        }\n",
    "\n",
    "    def pmx_crossover(self, parent1, parent2):\n",
    "        \"\"\"\n",
    "        Perform Partially Mapped Crossover (PMX) for permutation representation.\n",
    "        \n",
    "        Args:\n",
    "            parent1 (dict): First parent individual\n",
    "            parent2 (dict): Second parent individual\n",
    "            \n",
    "        Returns:\n",
    "            dict: Offspring individual created by crossover\n",
    "        \"\"\"\n",
    "        size = len(parent1['customer_sequence'])  # Length of customer sequence\n",
    "        p1, p2 = parent1['customer_sequence'], parent2['customer_sequence']  # Extract sequences\n",
    "        \n",
    "        if size < 2:  # Edge case: single customer\n",
    "            return self.create_individual(p1[:])\n",
    "        \n",
    "        start, end = sorted(random.sample(range(size), 2))  # Random crossover segment\n",
    "        child = [None] * size  # Initialize offspring\n",
    "        \n",
    "        # Copy crossover segment from parent1\n",
    "        for i in range(start, end + 1):\n",
    "            child[i] = p1[i]\n",
    "        \n",
    "        # Create mapping from conflicting elements in parent2 to parent1\n",
    "        mapping = {p2[i]: p1[i] for i in range(start, end + 1) if p1[i] != p2[i]}\n",
    "        \n",
    "        # Fill remaining positions\n",
    "        for i in range(size):\n",
    "            if child[i] is None:  # Position needs to be filled\n",
    "                gene = p2[i]  # Start with parent2's gene\n",
    "                \n",
    "                # Follow mapping chain to resolve conflicts\n",
    "                while gene in mapping:\n",
    "                    gene = mapping[gene]\n",
    "                \n",
    "                # Final conflict resolution: use available customer\n",
    "                if gene in child:\n",
    "                    available = set(self.customer_range) - set(g for g in child if g is not None)\n",
    "                    gene = available.pop() if available else p2[i]\n",
    "                \n",
    "                child[i] = gene  # Assign resolved gene\n",
    "        \n",
    "        return self.create_individual(child)  # Create complete individual\n",
    "\n",
    "    def insert_mutation(self, individual):\n",
    "        \"\"\"\n",
    "        Apply insert mutation operator specifically designed for VRP optimization.\n",
    "        \n",
    "        Insert mutation removes a randomly selected customer from one position\n",
    "        and inserts it at a different random position. This type of mutation\n",
    "        is particularly effective for VRP problems because:\n",
    "        - It preserves most of the tour structure while making meaningful changes\n",
    "        - Often improves route efficiency by relocating customers\n",
    "        - Provides good balance between exploration and exploitation\n",
    "        \n",
    "        Args:\n",
    "            individual (dict): Individual to mutate\n",
    "            \n",
    "        Returns:\n",
    "            dict: New individual after mutation (original unchanged)\n",
    "            \n",
    "        Example:\n",
    "            Original: [1, 2, 3, 4, 5]\n",
    "            Remove customer 3 from position 2, insert at position 0\n",
    "            Result: [3, 1, 2, 4, 5]\n",
    "        \"\"\"\n",
    "        seq = individual['customer_sequence'][:]  # Copy sequence to avoid modifying original\n",
    "        \n",
    "        if random.random() < self.mutation_rate:  # Apply mutation with given probability\n",
    "            if len(seq) > 2:  # Need at least 3 customers for meaningful insert mutation\n",
    "                i = random.randint(0, len(seq)-1)  # Source position (customer to move)\n",
    "                j = random.randint(0, len(seq)-1)  # Target position (where to insert)\n",
    "                \n",
    "                if i != j:  # Only mutate if positions are different\n",
    "                    gene = seq.pop(i)  # Remove customer from source position\n",
    "                    seq.insert(j, gene)  # Insert customer at target position\n",
    "        \n",
    "        return self.create_individual(seq)  # Create new individual with mutated sequence\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the main NSGA-II algorithm loop with insert mutation.\n",
    "        \n",
    "        Implements the complete NSGA-II procedure:\n",
    "        1. Initialize population with heuristics and random solutions\n",
    "        2. Evaluate initial population\n",
    "        3. Perform non-dominated sorting and crowding distance calculation\n",
    "        4. For each generation:\n",
    "           - Create offspring through selection, crossover, and insert mutation\n",
    "           - Evaluate offspring population\n",
    "           - Combine parent and offspring populations\n",
    "           - Perform environmental selection using NSGA-II criteria\n",
    "           - Select best individuals for next generation\n",
    "        \n",
    "        Returns:\n",
    "            list: Final population after evolution (Pareto front approximation)\n",
    "        \"\"\"\n",
    "        # Phase 1: Initialize population\n",
    "        self.population = self.generate_initial_population()  # Create initial population\n",
    "        self.evaluate_population(self.population)  # Evaluate fitness\n",
    "        self.fast_non_dominated_sort(self.population)  # Assign dominance ranks\n",
    "        self.calculate_crowding_distance(self.population)  # Calculate diversity measure\n",
    "        \n",
    "        # Phase 2: Evolution loop\n",
    "        for gen in range(1, self.generations + 1):  # For each generation\n",
    "            offspring = []  # Initialize offspring population\n",
    "            \n",
    "            # Create offspring population\n",
    "            for _ in range(self.pop_size):\n",
    "                # Selection: Choose parents using tournament selection\n",
    "                parent1 = self.tournament_selection(self.population)\n",
    "                parent2 = self.tournament_selection(self.population)\n",
    "                \n",
    "                # Crossover: Create child with given probability\n",
    "                if random.random() < self.crossover_rate:\n",
    "                    child = self.pmx_crossover(parent1, parent2)  # PMX crossover\n",
    "                else:\n",
    "                    child = self.create_individual(parent1['customer_sequence'][:])  # Clone parent1\n",
    "                \n",
    "                # Mutation: Apply insert mutation operator\n",
    "                child = self.insert_mutation(child)  # Use insert mutation instead of swap\n",
    "                offspring.append(child)  # Add to offspring population\n",
    "            \n",
    "            # Evaluate new offspring\n",
    "            self.evaluate_population(offspring)\n",
    "            \n",
    "            # Environmental selection: Combine and select best\n",
    "            combined = self.population + offspring  # Combine parent and offspring (2*pop_size)\n",
    "            self.fast_non_dominated_sort(combined)  # Rank all individuals\n",
    "            self.calculate_crowding_distance(combined)  # Calculate diversity\n",
    "            \n",
    "            # Select best pop_size individuals for next generation\n",
    "            combined.sort(key=lambda x: (x['rank'], -x['crowding_distance']))\n",
    "            self.population = combined[:self.pop_size]  # Keep best individuals\n",
    "        \n",
    "        return self.population  # Return final Pareto front approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696daef4",
   "metadata": {},
   "source": [
    "## SPEA2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a36815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class SPEA2():\n",
    "\n",
    "    def __init__(self, data, pop_size=10, archive_size=10, generations=5, mutation_rate=0.3, crossover_rate=0.7):\n",
    "        self.data = data\n",
    "        self.pop_size = pop_size\n",
    "        self.archive_size = archive_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "        # Pre-cache frequently accessed values from data\n",
    "        self.dist_matrix = self.data['dist_matrix']\n",
    "        self.capacity = int(self.data['metadata']['CAPACITY'])\n",
    "        self.demands = self.data['demands']\n",
    "        self.n_customers = len(self.data['coords']) - 1\n",
    "        self.customer_range = list(range(1, self.n_customers + 1))\n",
    "\n",
    "    def nearest_neighbor_solution(self):\n",
    "        \"\"\"Distance-optimized solution\"\"\"\n",
    "        unvisited = set(self.customer_range)\n",
    "        solution = []\n",
    "        current = 0\n",
    "        while unvisited:\n",
    "            distances = [(self.dist_matrix[current, customer], customer)\n",
    "                        for customer in unvisited]\n",
    "            _, next_customer = min(distances)\n",
    "            solution.append(next_customer)\n",
    "            unvisited.remove(next_customer)\n",
    "            current = next_customer\n",
    "        return solution\n",
    "\n",
    "    def balanced_insertion_solution(self):\n",
    "        \"\"\"Balance-focused solution\"\"\"\n",
    "        customers_by_distance = [(self.dist_matrix[0, c], c) for c in self.customer_range]\n",
    "        customers_by_distance.sort()\n",
    "        solution = []\n",
    "        near = [c for _, c in customers_by_distance[:len(customers_by_distance)//2]]\n",
    "        far = [c for _, c in customers_by_distance[len(customers_by_distance)//2:]]\n",
    "        for i in range(max(len(near), len(far))):\n",
    "            if i < len(near):\n",
    "                solution.append(near[i])\n",
    "            if i < len(far):\n",
    "                solution.append(far[i])\n",
    "        return solution\n",
    "    \n",
    "    def split_routes(self, customer_sequence):\n",
    "        \"\"\"Route splitting with capacity constraints\"\"\"\n",
    "        routes, route, load = [], [0], 0\n",
    "        for customer in customer_sequence:\n",
    "            demand = self.demands[customer]\n",
    "            if load + demand > self.capacity:\n",
    "                route.append(0)\n",
    "                routes.append(route)\n",
    "                route, load = [0, customer], demand\n",
    "            else:\n",
    "                route.append(customer)\n",
    "                load += demand\n",
    "        route.append(0)\n",
    "        routes.append(route)\n",
    "        return routes\n",
    "\n",
    "    def calculate_route_distance(self, route):\n",
    "        \"\"\"Calculate distance for a single route\"\"\"\n",
    "        return sum(self.dist_matrix[route[i], route[i+1]] for i in range(len(route) - 1))\n",
    "\n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"Assignment-compliant: Total Distance vs Standard Deviation\"\"\"\n",
    "        if individual['objectives'] is not None:\n",
    "            return\n",
    "        routes = individual['routes']\n",
    "        route_distances = [self.calculate_route_distance(route) for route in routes]\n",
    "        total_dist = sum(route_distances)\n",
    "        if len(route_distances) > 1:\n",
    "            mean_length = total_dist / len(route_distances)\n",
    "            variance = sum((d - mean_length)**2 for d in route_distances) / len(route_distances)\n",
    "            route_balance = variance**0.5  # Standard deviation\n",
    "        else:\n",
    "            route_balance = 0.0\n",
    "        individual['objectives'] = [total_dist, route_balance]\n",
    "\n",
    "    def evaluate_population(self, population):\n",
    "        for individual in population:\n",
    "            self.evaluate_individual(individual)\n",
    "            \n",
    "    def create_individual(self, customer_sequence):\n",
    "        \"\"\"Out of a random sequence of customer visits, applies constraints to it\"\"\"\n",
    "        return {\n",
    "            'customer_sequence': customer_sequence,  # A random customer sequence\n",
    "            'routes': self.split_routes(customer_sequence),  # Applies constraints\n",
    "            'objectives': None,  # Where the evaluation of the route is stored\n",
    "        }\n",
    "    \n",
    "    def domination_function(self, indiv_1, indiv_2):\n",
    "        \"\"\"Checks if indiv_1 weakly dominates indiv_2 in objective space, works only with 2 objectives to optimize\"\"\"\n",
    "        x_1, y_1 = indiv_1['objectives']  # Retrieve Objectives from indiv_1\n",
    "        x_2, y_2 = indiv_2['objectives']  # Retrieve Objectives from indiv_2\n",
    "\n",
    "        if (x_1 <= x_2 and y_1 <= y_2):  # Check for weak domination by seeing if objectives are better or equal\n",
    "            return True  # If True return True // indiv_1 weakly dominates indiv_2\n",
    "        else:\n",
    "            return False  # If False return False // indiv_1 does not dominate indiv_2\n",
    "\n",
    "    def raw_fitness_function(self, population):\n",
    "        \"\"\"Calculates the raw fitness value of each individual in the population\"\"\"\n",
    "        strength = np.zeros(len(population))  # Initialize array for strength values, 1 for each indiv\n",
    "        raw_fitness = np.zeros(len(population))  # FIXED: Initialize with zeros instead of ones\n",
    "        \n",
    "        # Calculate strength values\n",
    "        for i in range(len(population)):  # Iterate through population\n",
    "            for j in range(len(population)):  # Iterate through population\n",
    "                if i != j:  # If not the same individual\n",
    "                    if self.domination_function(population[i], population[j]):  # If i weakly dominates j\n",
    "                        strength[i] += 1  # Increase strength of i by one\n",
    "        \n",
    "        # Calculate raw fitness values\n",
    "        for i in range(len(population)):  # Iterate through population\n",
    "            for j in range(len(population)):  # Iterate through population\n",
    "                if i != j:  # If not the same individual\n",
    "                    if self.domination_function(population[j], population[i]):  # If j weakly dominates i\n",
    "                        raw_fitness[i] += strength[j]  # Add the strength of j to raw fitness value for i\n",
    "                        \n",
    "        return raw_fitness\n",
    "\n",
    "    def euclidean_distance(self, p1, p2):\n",
    "        x_1, y_1 = p1\n",
    "        x_2, y_2 = p2\n",
    "        return np.sqrt((x_2 - x_1)**2 + (y_2 - y_1)**2)\n",
    "    \n",
    "    def density_measure_function(self, population):\n",
    "        \"\"\"FIXED: Density measure function to avoid index out of bounds\"\"\"\n",
    "        pop_size = len(population)\n",
    "        if pop_size <= 2:\n",
    "            # For very small populations, return zero density\n",
    "            return np.zeros(pop_size)\n",
    "            \n",
    "        distances = np.zeros((pop_size, pop_size))\n",
    "        \n",
    "        # Calculate distance matrix\n",
    "        for i in range(pop_size):\n",
    "            indiv_1 = population[i]\n",
    "            for j in range(pop_size):\n",
    "                indiv_2 = population[j]\n",
    "                distances[i, j] = self.euclidean_distance(indiv_1['objectives'], indiv_2['objectives'])\n",
    "        \n",
    "        # Sort distances for each individual\n",
    "        distances = np.sort(distances, axis=1)\n",
    "        \n",
    "        # Calculate k-th nearest neighbor distance (k should be valid index)\n",
    "        k = max(1, min(int(np.sqrt(pop_size)), pop_size - 1))  # FIXED: Ensure k is valid\n",
    "        \n",
    "        density_measure = []\n",
    "        for i in range(pop_size):\n",
    "            # Use k-th nearest neighbor distance (skip distance 0 to self)\n",
    "            kth_distance = distances[i, k] if k < pop_size else distances[i, -1]\n",
    "            density_measure.append(1.0 / (2.0 + kth_distance))  # FIXED: Proper formula\n",
    "        \n",
    "        return np.array(density_measure)\n",
    "    \n",
    "    def fitness_function(self, population):\n",
    "        raw_fitness = self.raw_fitness_function(population)\n",
    "        density_measure = self.density_measure_function(population)\n",
    "        fitness = raw_fitness + density_measure\n",
    "        return fitness\n",
    "\n",
    "    def sort_by_fitness(self, population, fitness):\n",
    "        idx = np.argsort(fitness)\n",
    "        new_population = []\n",
    "        new_fitness = []\n",
    "        for i in range(len(idx)):\n",
    "            new_population.append(population[idx[i]])\n",
    "            new_fitness.append(fitness[idx[i]])\n",
    "        return new_population, np.array(new_fitness)\n",
    "\n",
    "    def roulette_wheel(self, fitness_vals):\n",
    "        \"\"\"FIXED: Proper roulette wheel selection for minimization problems\"\"\"\n",
    "        if len(fitness_vals) == 0:\n",
    "            return 0\n",
    "            \n",
    "        # Convert fitness to selection probabilities (lower fitness = higher probability)\n",
    "        min_fitness = np.min(fitness_vals)\n",
    "        adjusted_fitness = fitness_vals - min_fitness + 1e-10  # Avoid division by zero\n",
    "        probabilities = 1.0 / (adjusted_fitness + 1e-10)  # Invert for minimization\n",
    "        probabilities = probabilities / np.sum(probabilities)  # Normalize\n",
    "        \n",
    "        # Cumulative probabilities\n",
    "        cumsum = np.cumsum(probabilities)\n",
    "        \n",
    "        # Select individual\n",
    "        random_val = np.random.rand()\n",
    "        for i in range(len(cumsum)):\n",
    "            if random_val <= cumsum[i]:\n",
    "                return i\n",
    "        return len(cumsum) - 1  # Fallback to last individual\n",
    "\n",
    "    def pmx_crossover(self, parent1, parent2):\n",
    "        \"\"\"PMX crossover\"\"\"\n",
    "        size = len(parent1['customer_sequence'])\n",
    "        p1, p2 = parent1['customer_sequence'], parent2['customer_sequence']\n",
    "        if size < 2:\n",
    "            return self.create_individual(p1[:])\n",
    "        start, end = sorted(random.sample(range(size), 2))\n",
    "        child = [None] * size\n",
    "        for i in range(start, end + 1):\n",
    "            child[i] = p1[i]\n",
    "        mapping = {p2[i]: p1[i] for i in range(start, end + 1) if p1[i] != p2[i]}\n",
    "        for i in range(size):\n",
    "            if child[i] is None:\n",
    "                gene = p2[i]\n",
    "                while gene in mapping:\n",
    "                    gene = mapping[gene]\n",
    "                if gene in child:\n",
    "                    available = set(self.customer_range) - set(g for g in child if g is not None)\n",
    "                    gene = available.pop() if available else p2[i]\n",
    "                child[i] = gene\n",
    "        return self.create_individual(child)\n",
    "\n",
    "    def swap_mutation(self, individual):\n",
    "        seq = individual['customer_sequence'][:]\n",
    "        if random.random() < self.mutation_rate:\n",
    "            mutation_type = random.choice(['swap', 'insert', 'reverse'])\n",
    "            if mutation_type == 'swap' and len(seq) > 1:\n",
    "                i, j = random.sample(range(len(seq)), 2)\n",
    "                seq[i], seq[j] = seq[j], seq[i]\n",
    "            elif mutation_type == 'insert' and len(seq) > 2:\n",
    "                i = random.randint(0, len(seq)-1)\n",
    "                j = random.randint(0, len(seq)-1)\n",
    "                if i != j:\n",
    "                    gene = seq.pop(i)\n",
    "                    seq.insert(j, gene)\n",
    "            elif mutation_type == 'reverse' and len(seq) > 2:\n",
    "                i, j = sorted(random.sample(range(len(seq)), 2))\n",
    "                seq[i:j+1] = reversed(seq[i:j+1])\n",
    "        return self.create_individual(seq)\n",
    "    \n",
    "    def breeding(self, population, fitness):\n",
    "        \"\"\"FIXED: Proper breeding with bounds checking\"\"\"\n",
    "        offspring = []\n",
    "        for i in range(self.pop_size):\n",
    "            parent1_idx = self.roulette_wheel(fitness)\n",
    "            parent2_idx = self.roulette_wheel(fitness)\n",
    "            \n",
    "            # Ensure different parents with bounds checking\n",
    "            attempts = 0\n",
    "            while parent1_idx == parent2_idx and attempts < 10:\n",
    "                parent2_idx = self.roulette_wheel(fitness)\n",
    "                attempts += 1\n",
    "                \n",
    "            parent1, parent2 = population[parent1_idx], population[parent2_idx]\n",
    "            \n",
    "            if random.random() < self.crossover_rate:\n",
    "                child = self.pmx_crossover(parent1, parent2)\n",
    "            else:\n",
    "                child = self.create_individual(parent1['customer_sequence'][:])\n",
    "            child = self.swap_mutation(child)\n",
    "            offspring.append(child)\n",
    "        return offspring\n",
    "            \n",
    "    def generate_initial_population(self):\n",
    "        population = []\n",
    "        # Add 2 heuristic solutions for better starting points\n",
    "        if self.pop_size >= 2:\n",
    "            nn_seq = self.nearest_neighbor_solution()\n",
    "            population.append(self.create_individual(nn_seq))\n",
    "            bal_seq = self.balanced_insertion_solution()\n",
    "            population.append(self.create_individual(bal_seq))\n",
    "            for _ in range(self.pop_size - 2):\n",
    "                perm = self.customer_range[:]\n",
    "                random.shuffle(perm)\n",
    "                population.append(self.create_individual(perm))\n",
    "        else:\n",
    "            for _ in range(self.pop_size):\n",
    "                perm = self.customer_range[:]\n",
    "                random.shuffle(perm)\n",
    "                population.append(self.create_individual(perm))\n",
    "        return population\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"FIXED: Main algorithm loop with proper copying and flow\"\"\"\n",
    "        # Initialize population and archive\n",
    "        self.population = self.generate_initial_population()\n",
    "        self.evaluate_population(self.population)\n",
    "        \n",
    "        # Initialize archive with copy of initial population\n",
    "        self.archive = [ind.copy() for ind in self.population]  # FIXED: Proper copying\n",
    "        \n",
    "        for generation in range(self.generations):  # FIXED: Proper loop structure\n",
    "            # Combine population and archive\n",
    "            combined_population = self.population + self.archive\n",
    "            \n",
    "            # Calculate fitness\n",
    "            fitness = self.fitness_function(combined_population)\n",
    "            \n",
    "            # Sort by fitness (lower is better)\n",
    "            combined_population, fitness = self.sort_by_fitness(combined_population, fitness)\n",
    "            \n",
    "            # Update archive (best individuals)\n",
    "            self.archive = combined_population[:self.archive_size]\n",
    "            \n",
    "            # Generate new population through breeding\n",
    "            archive_fitness = fitness[:self.archive_size]\n",
    "            self.population = self.breeding(self.archive, archive_fitness)\n",
    "            self.evaluate_population(self.population)\n",
    "            \n",
    "        return self.archive  # Return final archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e9251",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfa986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_assignment_format(results):\n",
    "    \"\"\"\n",
    "    Display the single comprehensive table required for Assignment 2.\n",
    "    \n",
    "    This table covers all requirements:\n",
    "    - Algorithm comparison (NSGA-II vs SPEA2)\n",
    "    - All test problems (Small, Medium, Large)\n",
    "    - All three parameter sets (Conservative, Balanced, Aggressive)\n",
    "    - Time analysis\n",
    "    - Convergence and diversity metrics\n",
    "    - Solution quality metrics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*130)\n",
    "    print(\"MULTI-OBJECTIVE VRP ALGORITHM COMPARISON - Assignment 2 Results\")\n",
    "    print(\"=\"*130)\n",
    "    \n",
    "    # Enhanced header with better spacing\n",
    "    print(f\"{'Algorithm':<8} {'Instance':<9} {'Parameter':<12} {'PF/Total':<9} {'Best Dist':<10} {'Best Bal':<9} {'Convergence':<11} {'Diversity':<10} {'Time(s)':<10}\")\n",
    "    print(\"-\" * 130)\n",
    "    \n",
    "    # Group by algorithm for better readability\n",
    "    nsga_results = [r for r in results if r['Algorithm'] == 'NSGAII']\n",
    "    spea_results = [r for r in results if r['Algorithm'] == 'SPEA2']\n",
    "    \n",
    "    # Display NSGA-II results\n",
    "    if nsga_results:\n",
    "        print(\"NSGA-II Results:\")\n",
    "        print(\"-\" * 130)\n",
    "        for r in nsga_results:\n",
    "            div_str = f\"{r['Diversity']:.3f}\" if r['Diversity'] > 0 else \"N/A\"\n",
    "            pf_ratio = f\"{r['Front_Size']}/{r['Total_Solutions']}\"\n",
    "            time_str = f\"{r['Time']:.3f}±{r.get('Time_Std', 0):.3f}\"\n",
    "            \n",
    "            print(f\"{'NSGA-II':<8} {r['Instance']:<9} {r['Parameter']:<12} {pf_ratio:<9} \"\n",
    "                  f\"{r['Best_Distance']:<10.1f} {r['Best_Balance']:<9.2f} \"\n",
    "                  f\"{r['Convergence']:<11.0f} {div_str:<10} {time_str:<10}\")\n",
    "    \n",
    "    print(\"-\" * 130)\n",
    "    \n",
    "    # Display SPEA2 results\n",
    "    if spea_results:\n",
    "        print(\"SPEA2 Results:\")\n",
    "        print(\"-\" * 130)\n",
    "        for r in spea_results:\n",
    "            div_str = f\"{r['Diversity']:.3f}\" if r['Diversity'] > 0 else \"N/A\"\n",
    "            pf_ratio = f\"{r['Front_Size']}/{r['Total_Solutions']}\"\n",
    "            time_str = f\"{r['Time']:.3f}±{r.get('Time_Std', 0):.3f}\"\n",
    "            \n",
    "            print(f\"{'SPEA2':<8} {r['Instance']:<9} {r['Parameter']:<12} {pf_ratio:<9} \"\n",
    "                  f\"{r['Best_Distance']:<10.1f} {r['Best_Balance']:<9.2f} \"\n",
    "                  f\"{r['Convergence']:<11.0f} {div_str:<10} {time_str:<10}\")\n",
    "    \n",
    "    print(\"=\"*130)\n",
    "    \n",
    "\n",
    "def run_multi_algorithm_experiment(moea_classes, instance_files, param_sets, num_runs=5):\n",
    "    \"\"\"\n",
    "    Execute comprehensive multi-algorithm MOEA experiment with statistical analysis.\n",
    "    \n",
    "    This is the main experimental function that:\n",
    "    1. Verifies data file availability\n",
    "    2. Runs multiple algorithms across different parameter configurations\n",
    "    3. Collects timing and performance statistics\n",
    "    4. Performs statistical analysis across multiple runs\n",
    "    5. Generates comprehensive reports and visualizations\n",
    "    \n",
    "    Args:\n",
    "        moea_classes (list): List of (algorithm_name, algorithm_class) tuples to test\n",
    "        instance_files (list): List of (instance_name, file_path) tuples for test problems\n",
    "        param_sets (list): List of parameter configuration dictionaries\n",
    "        num_runs (int, optional): Number of independent runs per configuration. Defaults to 5.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (results, pareto_fronts, all_solutions) containing complete experimental data\n",
    "    \"\"\"\n",
    "    print(\"MULTI-ALGORITHM MOEA EXPERIMENT - Assignment 2\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Phase 1: Verify data availability and filter available files\n",
    "    available_files = []\n",
    "    print(\"\\n🔍 Checking data file availability...\")\n",
    "    for inst_name, inst_file in instance_files:\n",
    "        if os.path.exists(inst_file):\n",
    "            available_files.append((inst_name, inst_file))\n",
    "            print(f\"  ✅ {inst_name}: {inst_file}\")\n",
    "        else:\n",
    "            print(f\"  ❌ {inst_name}: {inst_file} (file not found)\")\n",
    "    \n",
    "    if not available_files:\n",
    "        print(\"\\n❌ No data files found! Please check file paths.\")\n",
    "        return [], {}, {}\n",
    "    \n",
    "    print(f\"\\n📊 Found {len(available_files)}/{len(instance_files)} data files\")\n",
    "    \n",
    "    # Initialize data collection structures\n",
    "    results = []  # Collect experimental results\n",
    "    pareto_fronts = {}  # Store Pareto fronts for visualization\n",
    "    all_solutions_dict = {}  # Store all solutions for analysis\n",
    "    data_cache = {}  # Cache parsed VRP data to avoid re-reading files\n",
    "    \n",
    "    # Phase 2: Execute experiments for each algorithm\n",
    "    for algo_name, algo_class in moea_classes:\n",
    "        print(f\"\\n🔬 Testing Algorithm: {algo_name}\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Phase 3: Test each parameter configuration\n",
    "        for params in param_sets:\n",
    "            param_name = params[\"name\"]  # Extract parameter set name\n",
    "            print(f\"\\n📊 Parameter Set: {param_name}\")\n",
    "            \n",
    "            # Phase 4: Test each available problem instance\n",
    "            for inst_name, inst_file in available_files:\n",
    "                print(f\"  📁 {inst_name}...\", end=\" \", flush=True)  # Progress indicator\n",
    "                \n",
    "                # Cache data loading to improve efficiency\n",
    "                if inst_file not in data_cache:\n",
    "                    try:\n",
    "                        data_cache[inst_file] = parse_vrp_file(inst_file)  # Parse and cache VRP data\n",
    "                        print(f\"(loaded)\", end=\" \")  # Indicate successful loading\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Error loading {inst_file}: {e}\")  # Report loading errors\n",
    "                        continue  # Skip this instance\n",
    "                        \n",
    "                data = data_cache[inst_file]  # Get cached data\n",
    "                \n",
    "                # Initialize statistics collection for multiple runs\n",
    "                all_run_solutions = []  # Collect all solutions across runs\n",
    "                run_times = []  # Collect execution times\n",
    "                successful_runs = 0  # Count successful completions\n",
    "                \n",
    "                # Phase 5: Execute multiple independent runs for statistical significance\n",
    "                for run in range(1, num_runs + 1):\n",
    "                    try:\n",
    "                        # Set reproducible random seeds for consistent results\n",
    "                        random.seed(run * 456)  # Different seed for each run\n",
    "                        np.random.seed(run * 456)  # Numpy random state\n",
    "                        \n",
    "                        # Create fresh algorithm instance with current parameters\n",
    "                        algorithm = algo_class(\n",
    "                            data=data,  # Problem instance data\n",
    "                            pop_size=params['pop_size'],  # Population size\n",
    "                            generations=params['generations'],  # Number of generations\n",
    "                            crossover_rate=params['crossover_rate'],  # Crossover probability\n",
    "                            mutation_rate=params['mutation_rate']  # Mutation probability\n",
    "                        )\n",
    "                        \n",
    "                        # Execute algorithm with timing measurement\n",
    "                        start_time = time.time()  # Start timing\n",
    "                        final_pop = algorithm.run()  # Run the algorithm\n",
    "                        run_time = time.time() - start_time  # Calculate elapsed time\n",
    "                        \n",
    "                        # Collect results from this run\n",
    "                        run_times.append(run_time)  # Store execution time\n",
    "                        all_run_solutions.extend(final_pop)  # Add solutions to collection\n",
    "                        successful_runs += 1  # Increment success counter\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Run {run} failed: {str(e)[:50]}...\")  # Report failures with truncated message\n",
    "                        continue  # Continue with next run\n",
    "                \n",
    "                # Phase 6: Process results if any runs succeeded\n",
    "                if all_run_solutions and successful_runs > 0:\n",
    "                    # Use NSGA-II for standardized Pareto front extraction\n",
    "                    temp_nsga = NSGAII(data=data, pop_size=10, generations=1)  # Temporary instance for sorting\n",
    "                    temp_nsga.fast_non_dominated_sort(all_run_solutions)  # Apply non-dominated sorting\n",
    "                    pareto_front = [sol for sol in all_run_solutions if sol.get('rank') == 1]  # Extract rank-1 solutions\n",
    "                    pareto_front.sort(key=lambda x: x['objectives'][0])  # Sort by first objective\n",
    "                    \n",
    "                    # Store results with unique key for later access\n",
    "                    key = f\"{inst_name}_{param_name}_{algo_name}\"  # Unique identifier\n",
    "                    pareto_fronts[key] = pareto_front  # Store Pareto front\n",
    "                    all_solutions_dict[key] = all_run_solutions  # Store all solutions\n",
    "                    \n",
    "                    # Calculate quality metrics for this configuration\n",
    "                    convergence, diversity = calculate_metrics(pareto_front)  # Quality assessment\n",
    "                    \n",
    "                    # Calculate statistical measures of execution time\n",
    "                    mean_time = np.mean(run_times)  # Average execution time\n",
    "                    std_time = np.std(run_times) if len(run_times) > 1 else 0  # Standard deviation\n",
    "                    \n",
    "                    # Create comprehensive result record\n",
    "                    results.append({\n",
    "                        'Algorithm': algo_name,  # Algorithm identifier\n",
    "                        'Instance': inst_name,  # Problem instance name\n",
    "                        'Parameter': param_name,  # Parameter set name\n",
    "                        'Front_Size': len(pareto_front),  # Number of Pareto-optimal solutions\n",
    "                        'Total_Solutions': len(all_run_solutions),  # Total solutions found\n",
    "                        'Best_Distance': min(ind['objectives'][0] for ind in pareto_front),  # Best distance found\n",
    "                        'Best_Balance': min(ind['objectives'][1] for ind in pareto_front),  # Best balance found\n",
    "                        'Convergence': convergence,  # Convergence quality metric\n",
    "                        'Diversity': diversity,  # Diversity quality metric\n",
    "                        'Time': mean_time,  # Average execution time\n",
    "                        'Time_Std': std_time,  # Time standard deviation\n",
    "                        'Evaluations': params['pop_size'] * params['generations'],  # Total evaluations\n",
    "                        'Successful_Runs': successful_runs  # Number of successful runs\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"✅ {successful_runs}/{num_runs} runs, {len(pareto_front)}/{len(all_run_solutions)} Pareto solutions\")\n",
    "                else:\n",
    "                    print(f\"❌ All {num_runs} runs failed\")  # Report complete failure\n",
    "    \n",
    "    # Phase 7: Generate comprehensive analysis and reports\n",
    "    if results:\n",
    "        # Display ONLY the required comprehensive table\n",
    "        display_results_assignment_format(results)\n",
    "        \n",
    "        # Keep the valuable visualizations for analysis\n",
    "        plot_algorithm_comparison(pareto_fronts)\n",
    "        plot_metrics_comparison(pareto_fronts)\n",
    "        \n",
    "        # Export results to CSV for further analysis\n",
    "        filename = f\"moea_comparison_results.csv\"\n",
    "        pd.DataFrame(results).to_csv(filename, index=False)\n",
    "        print(f\"\\n💾 Results saved to {filename}\")\n",
    "    else:\n",
    "        print(\"\\n❌ No results to display - all experiments failed!\")\n",
    "    \n",
    "    return results, pareto_fronts, all_solutions_dict\n",
    "\n",
    "\n",
    "# Keep the existing calculate_metrics and plot functions unchanged\n",
    "def calculate_metrics(pareto_front):\n",
    "    \"\"\"\n",
    "    Calculate convergence and diversity metrics for Pareto front quality assessment.\n",
    "    \"\"\"\n",
    "    if not pareto_front or len(pareto_front) < 2:\n",
    "        return 0, 0\n",
    "    \n",
    "    obj1 = [ind['objectives'][0] for ind in pareto_front]\n",
    "    obj2 = [ind['objectives'][1] for ind in pareto_front]\n",
    "    \n",
    "    # Convergence: Hypervolume approximation\n",
    "    ref_point = [max(obj1) * 1.1, max(obj2) * 1.1]\n",
    "    convergence = sum((ref_point[0] - o1) * (ref_point[1] - o2) for o1, o2 in zip(obj1, obj2))\n",
    "    \n",
    "    # Diversity: Spacing metric\n",
    "    if len(pareto_front) < 3:\n",
    "        diversity = 0\n",
    "    else:\n",
    "        distances = []\n",
    "        for i, ind1 in enumerate(pareto_front):\n",
    "            min_dist = min(((ind1['objectives'][0] - ind2['objectives'][0])**2 +\n",
    "                           (ind1['objectives'][1] - ind2['objectives'][1])**2)**0.5\n",
    "                          for j, ind2 in enumerate(pareto_front) if i != j)\n",
    "            distances.append(min_dist)\n",
    "        diversity = np.std(distances)\n",
    "        \n",
    "    return convergence, diversity\n",
    "\n",
    "\n",
    "def plot_algorithm_comparison(pareto_fronts):\n",
    "    \"\"\"Generate algorithm comparison plots across different instance sizes.\"\"\"\n",
    "    algo_colors = {\n",
    "        'NSGAII': {'Conservative': '#1f77b4', 'Balanced': '#ff7f0e', 'Aggressive': '#2ca02c'},\n",
    "        'SPEA2': {'Conservative': '#d62728', 'Balanced': '#9467bd', 'Aggressive': '#8c564b'}\n",
    "    }\n",
    "    \n",
    "    groups = ['Small', 'Medium', 'Large']\n",
    "    algorithms = list(set(key.split('_')[2] for key in pareto_fronts.keys()))\n",
    "    algorithms = [algo for algo in algorithms if algo in ['NSGAII', 'SPEA2']]\n",
    "    \n",
    "    for group in groups:\n",
    "        group_keys = []\n",
    "        for key in pareto_fronts.keys():\n",
    "            if pareto_fronts[key]:\n",
    "                key_parts = key.split('_')\n",
    "                if any(group.lower() in part.lower() for part in key_parts):\n",
    "                    group_keys.append(key)\n",
    "        \n",
    "        if len(group_keys) == 0:\n",
    "            continue\n",
    "            \n",
    "        fig, axes = plt.subplots(1, len(algorithms) if len(algorithms) > 1 else 1, \n",
    "                                figsize=(6*max(len(algorithms), 1), 6))\n",
    "        if len(algorithms) == 1:\n",
    "            axes = [axes]\n",
    "        elif len(algorithms) == 0:\n",
    "            continue\n",
    "        \n",
    "        for algo_idx, algorithm in enumerate(algorithms):\n",
    "            ax = axes[algo_idx] if len(algorithms) > 1 else axes[0]\n",
    "            colors = algo_colors.get(algorithm, {'Conservative': '#888888', 'Balanced': '#999999', 'Aggressive': '#aaaaaa'})\n",
    "            \n",
    "            for param in ['Conservative', 'Balanced', 'Aggressive']:\n",
    "                points = []\n",
    "                for key, front in pareto_fronts.items():\n",
    "                    if front and algorithm in key and param in key:\n",
    "                        key_parts = key.split('_')\n",
    "                        if any(group.lower() in part.lower() for part in key_parts):\n",
    "                            points.extend([(ind['objectives'][0], ind['objectives'][1]) for ind in front])\n",
    "                \n",
    "                if len(points) < 1:\n",
    "                    continue\n",
    "                    \n",
    "                points = sorted(set(points))\n",
    "                \n",
    "                pareto_points = []\n",
    "                for i, (x1, y1) in enumerate(points):\n",
    "                    dominated = any(x2 <= x1 and y2 <= y1 and (x2 < x1 or y2 < y1) \n",
    "                                  for j, (x2, y2) in enumerate(points) if i != j)\n",
    "                    if not dominated:\n",
    "                        pareto_points.append((x1, y1))\n",
    "                \n",
    "                pareto_points.sort()\n",
    "                \n",
    "                if len(pareto_points) >= 1:\n",
    "                    x_vals = [p[0] for p in pareto_points]\n",
    "                    y_vals = [p[1] for p in pareto_points]\n",
    "                    \n",
    "                    if len(pareto_points) == 1:\n",
    "                        ax.scatter(x_vals, y_vals, color=colors[param], s=100, alpha=0.8, \n",
    "                                 label=f\"{param} (n={len(pareto_points)})\",\n",
    "                                 edgecolors='white', linewidth=2)\n",
    "                    else:\n",
    "                        ax.plot(x_vals, y_vals, 'o-', color=colors[param], \n",
    "                               linewidth=3, markersize=8, alpha=0.8, \n",
    "                               label=f\"{param} (n={len(pareto_points)})\",\n",
    "                               markerfacecolor='white', markeredgewidth=2, \n",
    "                               markeredgecolor=colors[param])\n",
    "            \n",
    "            ax.set_xlabel(\"Total Distance (minimize)\", fontweight='bold', fontsize=12)\n",
    "            if algo_idx == 0 or len(algorithms) == 1:\n",
    "                ax.set_ylabel(\"Route Balance - Std Dev (minimize)\", fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f\"{algorithm} - {group} Instances\", fontweight='bold', fontsize=14)\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_ylim(bottom=0)\n",
    "            \n",
    "            if algo_idx == 0 or len(algorithms) == 1:\n",
    "                ax.legend(frameon=True, fancybox=True, shadow=True, loc='upper right')\n",
    "            \n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f\"Algorithm Comparison - {group} Instances\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_metrics_comparison(pareto_fronts):\n",
    "    \"\"\"Generate performance metrics comparison plots across algorithms.\"\"\"\n",
    "    algorithms = set()\n",
    "    for key in pareto_fronts.keys():\n",
    "        parts = key.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            algorithms.add(parts[2])\n",
    "    \n",
    "    algorithms = sorted(list(algorithms))\n",
    "    \n",
    "    algo_metrics = {}\n",
    "    for algo in algorithms:\n",
    "        algo_metrics[algo] = {}\n",
    "        for key, front in pareto_fronts.items():\n",
    "            if front and algo in key:\n",
    "                parts = key.split('_')\n",
    "                param = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                if param not in algo_metrics[algo]:\n",
    "                    algo_metrics[algo][param] = {'conv': [], 'div': []}\n",
    "                conv, div = calculate_metrics(front)\n",
    "                algo_metrics[algo][param]['conv'].append(conv)\n",
    "                algo_metrics[algo][param]['div'].append(div if div > 0 else 0)\n",
    "    \n",
    "    params = ['Conservative', 'Balanced', 'Aggressive']\n",
    "    \n",
    "    if len(algorithms) > 1:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        ax3, ax4 = None, None\n",
    "    \n",
    "    algo_colors_simple = {'NSGAII': '#1f77b4', 'SPEA2': '#ff7f0e'}\n",
    "    \n",
    "    x = np.arange(len(params))\n",
    "    width = 0.35 if len(algorithms) > 1 else 0.6\n",
    "    \n",
    "    for i, algo in enumerate(algorithms):\n",
    "        if algo in algo_metrics:\n",
    "            conv_means = [np.mean(algo_metrics[algo][p]['conv']) if p in algo_metrics[algo] else 0 for p in params]\n",
    "            ax1.bar(x + i*width if len(algorithms) > 1 else x, conv_means, width, \n",
    "                   label=algo, color=algo_colors_simple.get(algo, '#888888'), alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('Convergence (Hypervolume) by Parameter Set', fontweight='bold')\n",
    "    ax1.set_xlabel('Parameter Set')\n",
    "    ax1.set_ylabel('Hypervolume')\n",
    "    ax1.set_xticks(x + width/2 if len(algorithms) > 1 else x)\n",
    "    ax1.set_xticklabels(params)\n",
    "    if len(algorithms) > 1:\n",
    "        ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, algo in enumerate(algorithms):\n",
    "        if algo in algo_metrics:\n",
    "            div_means = [np.mean(algo_metrics[algo][p]['div']) if p in algo_metrics[algo] else 0 for p in params]\n",
    "            ax2.bar(x + i*width if len(algorithms) > 1 else x, div_means, width, \n",
    "                   label=algo, color=algo_colors_simple.get(algo, '#888888'), alpha=0.8)\n",
    "    \n",
    "    ax2.set_title('Diversity (Spacing) by Parameter Set', fontweight='bold')\n",
    "    ax2.set_xlabel('Parameter Set')\n",
    "    ax2.set_ylabel('Spacing')\n",
    "    ax2.set_xticks(x + width/2 if len(algorithms) > 1 else x)\n",
    "    ax2.set_xticklabels(params)\n",
    "    if len(algorithms) > 1:\n",
    "        ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(algorithms) > 1 and ax3 is not None and ax4 is not None:\n",
    "        algo_conv_overall = []\n",
    "        algo_div_overall = []\n",
    "        for algo in algorithms:\n",
    "            if algo in algo_metrics:\n",
    "                all_conv = [v for param_data in algo_metrics[algo].values() for v in param_data['conv']]\n",
    "                all_div = [v for param_data in algo_metrics[algo].values() for v in param_data['div']]\n",
    "                algo_conv_overall.append(np.mean(all_conv) if all_conv else 0)\n",
    "                algo_div_overall.append(np.mean(all_div) if all_div else 0)\n",
    "            else:\n",
    "                algo_conv_overall.append(0)\n",
    "                algo_div_overall.append(0)\n",
    "        \n",
    "        ax3.bar(algorithms, algo_conv_overall, \n",
    "               color=[algo_colors_simple.get(a, '#888888') for a in algorithms], alpha=0.8)\n",
    "        ax3.set_title('Overall Convergence Comparison', fontweight='bold')\n",
    "        ax3.set_ylabel('Average Hypervolume')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax4.bar(algorithms, algo_div_overall, \n",
    "               color=[algo_colors_simple.get(a, '#888888') for a in algorithms], alpha=0.8)\n",
    "        ax4.set_title('Overall Diversity Comparison', fontweight='bold')\n",
    "        ax4.set_ylabel('Average Spacing')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(\"Multi-Algorithm Performance Comparison\", fontsize=16, fontweight='bold')\n",
    "    else:\n",
    "        plt.suptitle(\"NSGA-II Performance Metrics\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Experimental Configuration and Execution ---\n",
    "\n",
    "moea_classes = [\n",
    "    (\"NSGAII\", NSGAII),  # Non-dominated Sorting Genetic Algorithm II\n",
    "    (\"SPEA2\", SPEA2)     # Strength Pareto Evolutionary Algorithm 2\n",
    "]\n",
    "\n",
    "# Define test problem instances across different complexity levels\n",
    "instance_files = [\n",
    "    (\"Small1\", \"data/Small.vrp\"),      \n",
    "    (\"Small2\", \"data/Small2.vrp\"),     \n",
    "    (\"Medium1\", \"data/Medium.vrp\"),   \n",
    "    (\"Medium2\", \"data/Medium2.vrp\"),   \n",
    "    (\"Large1\", \"data/Large.vrp\"),      \n",
    "    (\"Large2\", \"data/Large2.vrp\")     \n",
    "]\n",
    "\n",
    "param_sets = [\n",
    "    {\"name\": \"Conservative\", \"pop_size\": 60, \"generations\": 25, \"crossover_rate\": 0.5, \"mutation_rate\": 0.05},\n",
    "    {\"name\": \"Balanced\", \"pop_size\": 40, \"generations\": 40, \"crossover_rate\": 0.8, \"mutation_rate\": 0.2},\n",
    "    {\"name\": \"Aggressive\", \"pop_size\": 25, \"generations\": 80, \"crossover_rate\": 0.95, \"mutation_rate\": 0.5}\n",
    "]\n",
    "\n",
    "# Execute comprehensive experimental study with statistical significance\n",
    "results, pareto_fronts, all_solutions = run_multi_algorithm_experiment(\n",
    "    moea_classes,   \n",
    "    instance_files,  \n",
    "    param_sets,      \n",
    "    num_runs=20      \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in3050",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
