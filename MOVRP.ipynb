{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e4271e",
   "metadata": {},
   "source": [
    "# Multi-Objective Capacitated VRP (MOVRP) Problem Using Multi-Objective Evolutionary Algorithms (MOEAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641a026",
   "metadata": {},
   "source": [
    "### Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def parse_vrp_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Strip whitespace and filter empty lines\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Parse metadata\n",
    "    metadata = {}\n",
    "    i = 0\n",
    "    while not lines[i].startswith('NODE_COORD_SECTION'):\n",
    "        if ':' in lines[i]:\n",
    "            key, value = lines[i].split(':', 1)\n",
    "            metadata[key.strip()] = value.strip().strip('\"')\n",
    "        i += 1\n",
    "\n",
    "    # Parse node coordinates (1-based in file, but we'll make 0-based list)\n",
    "    coords = []\n",
    "    i += 1  # Skip section header\n",
    "    while not lines[i].startswith('DEMAND_SECTION'):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) == 3:\n",
    "            node_id = int(parts[0]) - 1  # Make 0-based\n",
    "            x, y = int(parts[1]), int(parts[2])\n",
    "            # Insert at correct index in case not sequential (though they usually are)\n",
    "            while len(coords) <= node_id:\n",
    "                coords.append(None)\n",
    "            coords[node_id] = (x, y)\n",
    "        i += 1\n",
    "\n",
    "    # Parse demands (0-based list)\n",
    "    demands = []\n",
    "    i += 1  # Skip section header\n",
    "    while not lines[i].startswith('DEPOT_SECTION'):\n",
    "        parts = lines[i].split()\n",
    "        if len(parts) == 2:\n",
    "            node_id = int(parts[0]) - 1  # Make 0-based\n",
    "            demand = int(parts[1])\n",
    "            while len(demands) <= node_id:\n",
    "                demands.append(None)\n",
    "            demands[node_id] = demand\n",
    "        i += 1\n",
    "\n",
    "    # Parse depot(s) ‚Äî usually just one, 1-based\n",
    "    depots = []\n",
    "    i += 1  # Skip section header\n",
    "    while i < len(lines) and lines[i] != 'EOF':\n",
    "        depot = int(lines[i])\n",
    "        if depot == -1:\n",
    "            break\n",
    "        depots.append(depot - 1)  # Make 0-based\n",
    "        i += 1\n",
    "\n",
    "    # Compute distance matrix (Euclidean 2D)\n",
    "    dimension = int(metadata.get('DIMENSION', len(coords)))\n",
    "    dist_matrix = np.zeros((dimension, dimension))\n",
    "    for a in range(dimension):\n",
    "        for b in range(dimension):\n",
    "            x1, y1 = coords[a]\n",
    "            x2, y2 = coords[b]\n",
    "            dist_matrix[a][b] = math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "    return {\n",
    "        'metadata': metadata,\n",
    "        'coords': coords,  # List of (x, y) tuples, 0-based (index 0 = node 1)\n",
    "        'demands': demands,  # List of integers, 0-based\n",
    "        'depots': depots,  # List of 0-based indices (usually [0] for depot at node 1)\n",
    "        'dist_matrix': dist_matrix  # Numpy array of floats\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41a893",
   "metadata": {},
   "source": [
    "## NSGA-II Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NSGA-II Implementation (cleaned) ---\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "class NSGAII:\n",
    "    def __init__(self, data, pop_size=20, generations=10, crossover_rate=0.7, mutation_rate=0.2):\n",
    "        self.data = data\n",
    "        self.pop_size = pop_size\n",
    "        self.generations = generations\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.population = []\n",
    "\n",
    "        # Pre-compute frequently accessed values\n",
    "        self.dist_matrix = self.data['dist_matrix']\n",
    "        self.capacity = int(self.data['metadata']['CAPACITY'])\n",
    "        self.demands = self.data['demands']\n",
    "        self.n_customers = len(self.data['coords']) - 1\n",
    "        self.customer_range = list(range(1, self.n_customers + 1))\n",
    "\n",
    "    def split_routes(self, customer_sequence):\n",
    "        \"\"\"Route splitting with capacity constraints\"\"\"\n",
    "        routes, route, load = [], [0], 0\n",
    "        for customer in customer_sequence:\n",
    "            demand = self.demands[customer]\n",
    "            if load + demand > self.capacity:\n",
    "                route.append(0)\n",
    "                routes.append(route)\n",
    "                route, load = [0, customer], demand\n",
    "            else:\n",
    "                route.append(customer)\n",
    "                load += demand\n",
    "        route.append(0)\n",
    "        routes.append(route)\n",
    "        return routes\n",
    "\n",
    "    def calculate_route_distance(self, route):\n",
    "        \"\"\"Calculate distance for a single route\"\"\"\n",
    "        return sum(self.dist_matrix[route[i], route[i+1]] for i in range(len(route) - 1))\n",
    "\n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"Assignment-compliant: Total Distance vs Standard Deviation\"\"\"\n",
    "        if individual['objectives'] is not None:\n",
    "            return\n",
    "        routes = individual['routes']\n",
    "        route_distances = [self.calculate_route_distance(route) for route in routes]\n",
    "        total_dist = sum(route_distances)\n",
    "        if len(route_distances) > 1:\n",
    "            mean_length = total_dist / len(route_distances)\n",
    "            variance = sum((d - mean_length)**2 for d in route_distances) / len(route_distances)\n",
    "            route_balance = variance**0.5  # Standard deviation\n",
    "        else:\n",
    "            route_balance = 0.0\n",
    "        individual['objectives'] = [total_dist, route_balance]\n",
    "\n",
    "    def evaluate_population(self, population):\n",
    "        for individual in population:\n",
    "            self.evaluate_individual(individual)\n",
    "\n",
    "    def generate_initial_population(self):\n",
    "        population = []\n",
    "        # Add 2 heuristic solutions for better starting points\n",
    "        if self.pop_size >= 2:\n",
    "            nn_seq = self.nearest_neighbor_solution()\n",
    "            population.append(self.create_individual(nn_seq))\n",
    "            bal_seq = self.balanced_insertion_solution()\n",
    "            population.append(self.create_individual(bal_seq))\n",
    "            for _ in range(self.pop_size - 2):\n",
    "                perm = self.customer_range[:]\n",
    "                random.shuffle(perm)\n",
    "                population.append(self.create_individual(perm))\n",
    "        else:\n",
    "            for _ in range(self.pop_size):\n",
    "                perm = self.customer_range[:]\n",
    "                random.shuffle(perm)\n",
    "                population.append(self.create_individual(perm))\n",
    "        return population\n",
    "\n",
    "    def nearest_neighbor_solution(self):\n",
    "        \"\"\"Distance-optimized solution\"\"\"\n",
    "        unvisited = set(self.customer_range)\n",
    "        solution = []\n",
    "        current = 0\n",
    "        while unvisited:\n",
    "            distances = [(self.dist_matrix[current, customer], customer)\n",
    "                        for customer in unvisited]\n",
    "            _, next_customer = min(distances)\n",
    "            solution.append(next_customer)\n",
    "            unvisited.remove(next_customer)\n",
    "            current = next_customer\n",
    "        return solution\n",
    "\n",
    "    def balanced_insertion_solution(self):\n",
    "        \"\"\"Balance-focused solution\"\"\"\n",
    "        customers_by_distance = [(self.dist_matrix[0, c], c) for c in self.customer_range]\n",
    "        customers_by_distance.sort()\n",
    "        solution = []\n",
    "        near = [c for _, c in customers_by_distance[:len(customers_by_distance)//2]]\n",
    "        far = [c for _, c in customers_by_distance[len(customers_by_distance)//2:]]\n",
    "        for i in range(max(len(near), len(far))):\n",
    "            if i < len(near):\n",
    "                solution.append(near[i])\n",
    "            if i < len(far):\n",
    "                solution.append(far[i])\n",
    "        return solution\n",
    "\n",
    "    def fast_non_dominated_sort(self, population):\n",
    "        \"\"\"Non-dominated sorting\"\"\"\n",
    "        n = len(population)\n",
    "        objectives = [ind['objectives'] for ind in population]\n",
    "        domination_count = [0] * n\n",
    "        dominated_solutions = [[] for _ in range(n)]\n",
    "        for i in range(n):\n",
    "            obj1_i, obj2_i = objectives[i]\n",
    "            for j in range(i + 1, n):\n",
    "                obj1_j, obj2_j = objectives[j]\n",
    "                if (obj1_i <= obj1_j and obj2_i <= obj2_j) and (obj1_i < obj1_j or obj2_i < obj2_j):\n",
    "                    dominated_solutions[i].append(j)\n",
    "                    domination_count[j] += 1\n",
    "                elif (obj1_j <= obj1_i and obj2_j <= obj2_i) and (obj1_j < obj1_i or obj2_j < obj2_i):\n",
    "                    dominated_solutions[j].append(i)\n",
    "                    domination_count[i] += 1\n",
    "        current_front = [i for i in range(n) if domination_count[i] == 0]\n",
    "        rank = 1\n",
    "        for i in current_front:\n",
    "            population[i]['rank'] = rank\n",
    "        while current_front:\n",
    "            next_front = []\n",
    "            for i in current_front:\n",
    "                for j in dominated_solutions[i]:\n",
    "                    domination_count[j] -= 1\n",
    "                    if domination_count[j] == 0:\n",
    "                        next_front.append(j)\n",
    "            if next_front:\n",
    "                rank += 1\n",
    "                for i in next_front:\n",
    "                    population[i]['rank'] = rank\n",
    "            current_front = next_front\n",
    "\n",
    "    def calculate_crowding_distance(self, population):\n",
    "        \"\"\"Calculate crowding distance\"\"\"\n",
    "        for ind in population:\n",
    "            ind['crowding_distance'] = 0.0\n",
    "        rank_groups = {}\n",
    "        for i, ind in enumerate(population):\n",
    "            rank = ind['rank']\n",
    "            if rank not in rank_groups:\n",
    "                rank_groups[rank] = []\n",
    "            rank_groups[rank].append(i)\n",
    "        for indices in rank_groups.values():\n",
    "            n_front = len(indices)\n",
    "            if n_front <= 2:\n",
    "                for i in indices:\n",
    "                    population[i]['crowding_distance'] = float('inf')\n",
    "                continue\n",
    "            for obj_idx in range(2):\n",
    "                indices.sort(key=lambda i: population[i]['objectives'][obj_idx])\n",
    "                population[indices[0]]['crowding_distance'] = float('inf')\n",
    "                population[indices[-1]]['crowding_distance'] = float('inf')\n",
    "                obj_range = population[indices[-1]]['objectives'][obj_idx] - population[indices[0]]['objectives'][obj_idx]\n",
    "                if obj_range > 0:\n",
    "                    for j in range(1, n_front - 1):\n",
    "                        i = indices[j]\n",
    "                        if population[i]['crowding_distance'] != float('inf'):\n",
    "                            prev_obj = population[indices[j-1]]['objectives'][obj_idx]\n",
    "                            next_obj = population[indices[j+1]]['objectives'][obj_idx]\n",
    "                            population[i]['crowding_distance'] += (next_obj - prev_obj) / obj_range\n",
    "\n",
    "    def tournament_selection(self, population, tournament_size=2):\n",
    "        \"\"\"Tournament selection\"\"\"\n",
    "        tournament = random.sample(population, tournament_size)\n",
    "        return min(tournament, key=lambda x: (x['rank'], -x['crowding_distance']))\n",
    "\n",
    "    def create_individual(self, customer_sequence):\n",
    "        \"\"\"Create individual from sequence\"\"\"\n",
    "        return {\n",
    "            'customer_sequence': customer_sequence,\n",
    "            'routes': self.split_routes(customer_sequence),\n",
    "            'objectives': None,\n",
    "            'rank': None,\n",
    "            'crowding_distance': 0.0\n",
    "        }\n",
    "\n",
    "    def pmx_crossover(self, parent1, parent2):\n",
    "        \"\"\"PMX crossover\"\"\"\n",
    "        size = len(parent1['customer_sequence'])\n",
    "        p1, p2 = parent1['customer_sequence'], parent2['customer_sequence']\n",
    "        if size < 2:\n",
    "            return self.create_individual(p1[:])\n",
    "        start, end = sorted(random.sample(range(size), 2))\n",
    "        child = [None] * size\n",
    "        for i in range(start, end + 1):\n",
    "            child[i] = p1[i]\n",
    "        mapping = {p2[i]: p1[i] for i in range(start, end + 1) if p1[i] != p2[i]}\n",
    "        for i in range(size):\n",
    "            if child[i] is None:\n",
    "                gene = p2[i]\n",
    "                while gene in mapping:\n",
    "                    gene = mapping[gene]\n",
    "                if gene in child:\n",
    "                    available = set(self.customer_range) - set(g for g in child if g is not None)\n",
    "                    gene = available.pop() if available else p2[i]\n",
    "                child[i] = gene\n",
    "        return self.create_individual(child)\n",
    "\n",
    "    def swap_mutation(self, individual):\n",
    "        seq = individual['customer_sequence'][:]\n",
    "        if random.random() < self.mutation_rate:\n",
    "            mutation_type = random.choice(['swap', 'insert', 'reverse'])\n",
    "            if mutation_type == 'swap' and len(seq) > 1:\n",
    "                i, j = random.sample(range(len(seq)), 2)\n",
    "                seq[i], seq[j] = seq[j], seq[i]\n",
    "            elif mutation_type == 'insert' and len(seq) > 2:\n",
    "                i = random.randint(0, len(seq)-1)\n",
    "                j = random.randint(0, len(seq)-1)\n",
    "                if i != j:\n",
    "                    gene = seq.pop(i)\n",
    "                    seq.insert(j, gene)\n",
    "            elif mutation_type == 'reverse' and len(seq) > 2:\n",
    "                i, j = sorted(random.sample(range(len(seq)), 2))\n",
    "                seq[i:j+1] = reversed(seq[i:j+1])\n",
    "        return self.create_individual(seq)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main NSGA-II algorithm\"\"\"\n",
    "        self.population = self.generate_initial_population()\n",
    "        self.evaluate_population(self.population)\n",
    "        self.fast_non_dominated_sort(self.population)\n",
    "        self.calculate_crowding_distance(self.population)\n",
    "        for gen in range(1, self.generations + 1):\n",
    "            offspring = []\n",
    "            for _ in range(self.pop_size):\n",
    "                parent1 = self.tournament_selection(self.population)\n",
    "                parent2 = self.tournament_selection(self.population)\n",
    "                if random.random() < self.crossover_rate:\n",
    "                    child = self.pmx_crossover(parent1, parent2)\n",
    "                else:\n",
    "                    child = self.create_individual(parent1['customer_sequence'][:])\n",
    "                child = self.swap_mutation(child)\n",
    "                offspring.append(child)\n",
    "            self.evaluate_population(offspring)\n",
    "            combined = self.population + offspring\n",
    "            self.fast_non_dominated_sort(combined)\n",
    "            self.calculate_crowding_distance(combined)\n",
    "            combined.sort(key=lambda x: (x['rank'], -x['crowding_distance']))\n",
    "            self.population = combined[:self.pop_size]\n",
    "        return self.population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696daef4",
   "metadata": {},
   "source": [
    "## SPEA2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a36815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7e9251",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9171c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Cell with multi-algorithm support ---\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_metrics(pareto_front):\n",
    "    \"\"\"Calculate convergence and diversity metrics\"\"\"\n",
    "    if not pareto_front or len(pareto_front) < 2:\n",
    "        return 0, 0\n",
    "    obj1 = [ind['objectives'][0] for ind in pareto_front]\n",
    "    obj2 = [ind['objectives'][1] for ind in pareto_front]\n",
    "    # Convergence: Hypervolume\n",
    "    ref_point = [max(obj1) * 1.1, max(obj2) * 1.1]\n",
    "    convergence = sum((ref_point[0] - o1) * (ref_point[1] - o2) for o1, o2 in zip(obj1, obj2))\n",
    "    # Diversity: Spacing\n",
    "    if len(pareto_front) < 3:\n",
    "        diversity = 0\n",
    "    else:\n",
    "        distances = []\n",
    "        for i, ind1 in enumerate(pareto_front):\n",
    "            min_dist = min(((ind1['objectives'][0] - ind2['objectives'][0])**2 +\n",
    "                           (ind1['objectives'][1] - ind2['objectives'][1])**2)**0.5\n",
    "                          for j, ind2 in enumerate(pareto_front) if i != j)\n",
    "            distances.append(min_dist)\n",
    "        diversity = np.std(distances)\n",
    "    return convergence, diversity\n",
    "\n",
    "def run_multi_algorithm_experiment(moea_classes, instance_files, param_sets, num_runs=5):\n",
    "    \"\"\"Complete multi-algorithm MOEA experiment with all solutions tracking\"\"\"\n",
    "    print(\"MULTI-ALGORITHM MOEA EXPERIMENT - Assignment 2\")\n",
    "    print(\"=\" * 60)\n",
    "    results = []\n",
    "    pareto_fronts = {}\n",
    "    all_solutions_dict = {}\n",
    "    data_cache = {}\n",
    "    \n",
    "    for algo_name, algo_class in moea_classes:\n",
    "        print(f\"\\nüî¨ Testing Algorithm: {algo_name}\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for params in param_sets:\n",
    "            param_name = params[\"name\"]\n",
    "            print(f\"\\nüìä Parameter Set: {param_name}\")\n",
    "            \n",
    "            for inst_name, inst_file in instance_files:\n",
    "                print(f\"  üìÅ {inst_name}...\", end=\" \")\n",
    "                \n",
    "                # Cache data loading\n",
    "                if inst_file not in data_cache:\n",
    "                    data_cache[inst_file] = parse_vrp_file(inst_file)\n",
    "                data = data_cache[inst_file]\n",
    "                \n",
    "                all_run_solutions = []\n",
    "                run_times = []\n",
    "                \n",
    "                # Multiple runs for statistical significance\n",
    "                for run in range(1, num_runs + 1):\n",
    "                    try:\n",
    "                        random.seed(run * 456)\n",
    "                        np.random.seed(run * 456)\n",
    "                        \n",
    "                        # Create algorithm instance\n",
    "                        algorithm = algo_class(\n",
    "                            data=data,\n",
    "                            pop_size=params['pop_size'],\n",
    "                            generations=params['generations'],\n",
    "                            crossover_rate=params['crossover_rate'],\n",
    "                            mutation_rate=params['mutation_rate']\n",
    "                        )\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        final_pop = algorithm.run()\n",
    "                        run_times.append(time.time() - start_time)\n",
    "                        all_run_solutions.extend(final_pop)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error in run {run}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # Process results if we have solutions\n",
    "                if all_run_solutions:\n",
    "                    # Use NSGA-II for final Pareto sorting (standardized)\n",
    "                    temp_nsga = NSGAII(data=data, pop_size=10, generations=1)\n",
    "                    temp_nsga.fast_non_dominated_sort(all_run_solutions)\n",
    "                    pareto_front = [sol for sol in all_run_solutions if sol.get('rank') == 1]\n",
    "                    pareto_front.sort(key=lambda x: x['objectives'][0])\n",
    "                    \n",
    "                    # Store results\n",
    "                    key = f\"{inst_name}_{param_name}_{algo_name}\"\n",
    "                    pareto_fronts[key] = pareto_front\n",
    "                    all_solutions_dict[key] = all_run_solutions\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    convergence, diversity = calculate_metrics(pareto_front)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Algorithm': algo_name,\n",
    "                        'Instance': inst_name,\n",
    "                        'Parameter': param_name,\n",
    "                        'Front_Size': len(pareto_front),\n",
    "                        'Total_Solutions': len(all_run_solutions),\n",
    "                        'Best_Distance': min(ind['objectives'][0] for ind in pareto_front),\n",
    "                        'Best_Balance': min(ind['objectives'][1] for ind in pareto_front),\n",
    "                        'Convergence': convergence,\n",
    "                        'Diversity': diversity,\n",
    "                        'Time': np.mean(run_times),\n",
    "                        'Evaluations': params['pop_size'] * params['generations']\n",
    "                    })\n",
    "                    print(f\"‚úÖ {len(pareto_front)}/{len(all_run_solutions)} Pareto solutions\")\n",
    "                else:\n",
    "                    print(\"‚ùå All runs failed\")\n",
    "    \n",
    "    # Display and save results\n",
    "    display_results(results)\n",
    "    plot_algorithm_comparison(pareto_fronts)\n",
    "    plot_metrics_comparison(pareto_fronts)\n",
    "    \n",
    "    # Save results with algorithm names\n",
    "    filename = f\"moea_comparison_results.csv\"\n",
    "    pd.DataFrame(results).to_csv(filename, index=False)\n",
    "    print(f\"\\nüíæ Results saved to {filename}\")\n",
    "    \n",
    "    return results, pareto_fronts, all_solutions_dict\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"Enhanced results display with algorithm comparison\"\"\"\n",
    "    print(f\"\\n{'Algorithm':<10} {'Instance':<8} {'Parameter':<12} {'PF/Total':<10} {'Distance':<9} {'Balance':<8} {'Convergence':<12} {'Diversity':<10} {'Time':<6}\")\n",
    "    print(\"=\" * 110)\n",
    "    for r in results:\n",
    "        div_str = f\"{r['Diversity']:.3f}\" if r['Diversity'] > 0 else \"N/A\"\n",
    "        pf_ratio = f\"{r['Front_Size']}/{r['Total_Solutions']}\"\n",
    "        print(f\"{r['Algorithm']:<10} {r['Instance']:<8} {r['Parameter']:<12} {pf_ratio:<10} \"\n",
    "              f\"{r['Best_Distance']:<9.1f} {r['Best_Balance']:<8.2f} \"\n",
    "              f\"{r['Convergence']:<12.0f} {div_str:<10} {r['Time']:<6.1f}\")\n",
    "\n",
    "def plot_algorithm_comparison(pareto_fronts):\n",
    "    \"\"\"Compare algorithms across different instance sizes\"\"\"\n",
    "    # Algorithm colors - add SPEA2 color when ready\n",
    "    algo_colors = {\n",
    "        'NSGAII': {'Conservative': '#1f77b4', 'Balanced': '#ff7f0e', 'Aggressive': '#2ca02c'},\n",
    "        # 'SPEA2': {'Conservative': '#d62728', 'Balanced': '#9467bd', 'Aggressive': '#8c564b'}  # Uncomment when SPEA2 is ready\n",
    "    }\n",
    "    \n",
    "    groups = ['Small', 'Medium', 'Large']\n",
    "    algorithms = list(algo_colors.keys())\n",
    "    \n",
    "    # Create subplot for each instance group\n",
    "    for group in groups:\n",
    "        fig, axes = plt.subplots(1, len(algorithms), figsize=(6*len(algorithms), 6))\n",
    "        if len(algorithms) == 1:\n",
    "            axes = [axes]  # Make it a list for consistency\n",
    "        \n",
    "        for algo_idx, algorithm in enumerate(algorithms):\n",
    "            ax = axes[algo_idx]\n",
    "            colors = algo_colors[algorithm]\n",
    "            \n",
    "            for param in ['Conservative', 'Balanced', 'Aggressive']:\n",
    "                # Collect points for this algorithm, parameter, and group\n",
    "                points = []\n",
    "                for key, front in pareto_fronts.items():\n",
    "                    if front and group in key and param in key and algorithm in key:\n",
    "                        points.extend([(ind['objectives'][0], ind['objectives'][1]) for ind in front])\n",
    "                \n",
    "                if len(points) < 3:\n",
    "                    continue\n",
    "                    \n",
    "                # Remove duplicates and sort\n",
    "                points = sorted(set(points))\n",
    "                \n",
    "                # Filter to keep only Pareto optimal points\n",
    "                pareto_points = []\n",
    "                for i, (x1, y1) in enumerate(points):\n",
    "                    dominated = any(x2 <= x1 and y2 <= y1 and (x2 < x1 or y2 < y1) \n",
    "                                  for j, (x2, y2) in enumerate(points) if i != j)\n",
    "                    if not dominated:\n",
    "                        pareto_points.append((x1, y1))\n",
    "                \n",
    "                # Sort and plot\n",
    "                pareto_points.sort()\n",
    "                \n",
    "                if len(pareto_points) >= 2:\n",
    "                    x_vals = [p[0] for p in pareto_points]\n",
    "                    y_vals = [p[1] for p in pareto_points]\n",
    "                    \n",
    "                    ax.plot(x_vals, y_vals, 'o-', color=colors[param], \n",
    "                           linewidth=3, markersize=8, alpha=0.8, \n",
    "                           label=f\"{param} (n={len(pareto_points)})\",\n",
    "                           markerfacecolor='white', markeredgewidth=2, \n",
    "                           markeredgecolor=colors[param])\n",
    "            \n",
    "            # Styling\n",
    "            ax.set_xlabel(\"Total Distance\", fontweight='bold', fontsize=12)\n",
    "            if algo_idx == 0:\n",
    "                ax.set_ylabel(\"Route Balance (Std Dev)\", fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f\"{algorithm} - {group}\", fontweight='bold', fontsize=14)\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_ylim(bottom=0)\n",
    "            \n",
    "            if algo_idx == 0:  # Legend only on first plot\n",
    "                ax.legend(frameon=True, fancybox=True, shadow=True, loc='upper right')\n",
    "            \n",
    "            # Clean up spines\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f\"Algorithm Comparison - {group} Instances\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_metrics_comparison(pareto_fronts):\n",
    "    \"\"\"Compare performance metrics across algorithms\"\"\"\n",
    "    algorithms = set()\n",
    "    for key in pareto_fronts.keys():\n",
    "        parts = key.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            algorithms.add(parts[2])  # Algorithm name is third part\n",
    "    \n",
    "    algorithms = sorted(list(algorithms))\n",
    "    \n",
    "    # Collect metrics by algorithm and parameter\n",
    "    algo_metrics = {}\n",
    "    for algo in algorithms:\n",
    "        algo_metrics[algo] = {}\n",
    "        for key, front in pareto_fronts.items():\n",
    "            if front and algo in key:\n",
    "                parts = key.split('_')\n",
    "                param = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                if param not in algo_metrics[algo]:\n",
    "                    algo_metrics[algo][param] = {'conv': [], 'div': []}\n",
    "                conv, div = calculate_metrics(front)\n",
    "                algo_metrics[algo][param]['conv'].append(conv)\n",
    "                algo_metrics[algo][param]['div'].append(div if div > 0 else 0)\n",
    "    \n",
    "    # Plot comparison\n",
    "    params = ['Conservative', 'Balanced', 'Aggressive']\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Color scheme for algorithms\n",
    "    algo_colors_simple = {'NSGAII': '#1f77b4', 'SPEA2': '#ff7f0e'}\n",
    "    \n",
    "    # Convergence by parameter\n",
    "    x = np.arange(len(params))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, algo in enumerate(algorithms):\n",
    "        if algo in algo_metrics:\n",
    "            conv_means = [np.mean(algo_metrics[algo][p]['conv']) if p in algo_metrics[algo] else 0 for p in params]\n",
    "            ax1.bar(x + i*width, conv_means, width, label=algo, color=algo_colors_simple.get(algo, '#888888'), alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('Convergence by Parameter Set', fontweight='bold')\n",
    "    ax1.set_xlabel('Parameter Set')\n",
    "    ax1.set_ylabel('Hypervolume')\n",
    "    ax1.set_xticks(x + width/2)\n",
    "    ax1.set_xticklabels(params)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Diversity by parameter\n",
    "    for i, algo in enumerate(algorithms):\n",
    "        if algo in algo_metrics:\n",
    "            div_means = [np.mean(algo_metrics[algo][p]['div']) if p in algo_metrics[algo] else 0 for p in params]\n",
    "            ax2.bar(x + i*width, div_means, width, label=algo, color=algo_colors_simple.get(algo, '#888888'), alpha=0.8)\n",
    "    \n",
    "    ax2.set_title('Diversity by Parameter Set', fontweight='bold')\n",
    "    ax2.set_xlabel('Parameter Set')\n",
    "    ax2.set_ylabel('Spacing')\n",
    "    ax2.set_xticks(x + width/2)\n",
    "    ax2.set_xticklabels(params)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overall algorithm comparison\n",
    "    algo_conv_overall = []\n",
    "    algo_div_overall = []\n",
    "    for algo in algorithms:\n",
    "        if algo in algo_metrics:\n",
    "            all_conv = [v for param_data in algo_metrics[algo].values() for v in param_data['conv']]\n",
    "            all_div = [v for param_data in algo_metrics[algo].values() for v in param_data['div']]\n",
    "            algo_conv_overall.append(np.mean(all_conv) if all_conv else 0)\n",
    "            algo_div_overall.append(np.mean(all_div) if all_div else 0)\n",
    "        else:\n",
    "            algo_conv_overall.append(0)\n",
    "            algo_div_overall.append(0)\n",
    "    \n",
    "    ax3.bar(algorithms, algo_conv_overall, color=[algo_colors_simple.get(a, '#888888') for a in algorithms], alpha=0.8)\n",
    "    ax3.set_title('Overall Convergence Comparison', fontweight='bold')\n",
    "    ax3.set_ylabel('Average Hypervolume')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax4.bar(algorithms, algo_div_overall, color=[algo_colors_simple.get(a, '#888888') for a in algorithms], alpha=0.8)\n",
    "    ax4.set_title('Overall Diversity Comparison', fontweight='bold')\n",
    "    ax4.set_ylabel('Average Spacing')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(\"Multi-Algorithm Performance Comparison\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Configuration and execution ---\n",
    "\n",
    "# ACTIVE: NSGA-II only for now\n",
    "moea_classes = [(\"NSGAII\", NSGAII)]\n",
    "\n",
    "# READY FOR SPEA2: Uncomment when SPEA2 class is implemented\n",
    "# moea_classes = [\n",
    "#     (\"NSGAII\", NSGAII),\n",
    "#     (\"SPEA2\", SPEA2)    # ‚Üê Add this when your group member implements SPEA2\n",
    "# ]\n",
    "\n",
    "instance_files = [\n",
    "    (\"Small1\", \"data/small.vrp\"),\n",
    "    (\"Small2\", \"data/small2.vrp\"),\n",
    "    (\"Medium1\", \"data/medium.vrp\"),\n",
    "    (\"Medium2\", \"data/medium2.vrp\"),\n",
    "    (\"Large1\", \"data/large.vrp\"),\n",
    "    (\"Large2\", \"data/large2.vrp\")\n",
    "]\n",
    "\n",
    "param_sets = [\n",
    "    {\"name\": \"Conservative\", \"pop_size\": 60, \"generations\": 25, \"crossover_rate\": 0.5, \"mutation_rate\": 0.05},\n",
    "    {\"name\": \"Balanced\", \"pop_size\": 40, \"generations\": 40, \"crossover_rate\": 0.8, \"mutation_rate\": 0.2},\n",
    "    {\"name\": \"Aggressive\", \"pop_size\": 25, \"generations\": 80, \"crossover_rate\": 0.95, \"mutation_rate\": 0.5}\n",
    "]\n",
    "\n",
    "# Run the experiment\n",
    "results, pareto_fronts, all_solutions = run_multi_algorithm_experiment(\n",
    "    moea_classes, instance_files, param_sets, num_runs=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in3050",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
